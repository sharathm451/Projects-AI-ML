{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f276af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    ! git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6545c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee18d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6711a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "                    fname = model_name,\n",
    "                    origin = base_url + model_file,\n",
    "                    untar = True)\n",
    "    \n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "    \n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    model = model.signatures['serving_default']\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83b492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,use_display_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5313f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b3f9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "    output_dict = model(input_tensor)\n",
    "    \n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy()\n",
    "                      for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "    \n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    if 'detection_masks' in output_dict:\n",
    "        \n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                output_dict['detection_masks'],output_dict['detection_boxes'],\n",
    "                image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                                          tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "        \n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "667ee6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def truck_detection(image,classes,scores,boxes):\n",
    "    for i in range(10):        \n",
    "        if (classes[i]==8 and scores[i]>0.5):\n",
    "            \n",
    "            h,w = image.shape[0:2]\n",
    "\n",
    "            ymin,xmin,ymax,xmax = boxes[i]\n",
    "            \n",
    "            now = datetime.now() \n",
    "            dt_string = now.strftime('%d_%m_%Y_%H_%M_%S')\n",
    "            \n",
    "            centre=(int(((xmin+xmax)/2)*w),int(((ymin+ymax)/2)*h))\n",
    "            cv2.circle(image,centre,10,(0,0,255),-1) # radius = 10, line thickness = -1 field circle\n",
    "\n",
    "            file_name = os.path.join('D:/ANACONDA/Project-9/source_material/models-master/research/object_detection/Custom_images',dt_string+'.jpg')\n",
    "            cv2.imwrite(file_name,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53946163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "    image_np = image_path\n",
    "    image_np = cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks = output_dict.get('detection_masks_reframed',None),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=2)\n",
    "    \n",
    "    image_np = cv2.cvtColor(image_np,cv2.COLOR_RGB2BGR)\n",
    "    truck_detection(image_np,output_dict['detection_classes'],output_dict['detection_scores'],\n",
    "                 output_dict['detection_boxes'])\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fbeea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(r'D:/ANACONDA/Project-9/source_material/models-master/research/object_detection/Custom_images/Pedestrian_video.mp4')\n",
    "i = 0 # frame counter\n",
    "while(True):\n",
    "    ret = video.grab()   # grab frame\n",
    "    i = i+1             # increment counter\n",
    "    if i % 3 == 0:       # display only one third of the frames, you can change this parameters according to your needs\n",
    "        ret, img = video.read()           # decode frame\n",
    "        img = show_inference(detection_model,img)\n",
    "        k=cv2.waitKey(1)\n",
    "        cv2.imshow('Live',img)\n",
    "        if(k==27):\n",
    "            break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c5f2028",
   "metadata": {},
   "source": [
    "reference bbox:\n",
    "    https://d2l.ai/chapter_computer-vision/bounding-box.html\n",
    "    \n",
    "Note: dont get confuse if x,y,w,h given and required x2,y2\n",
    "x+w = x2, y+h = y2\n",
    "syntax:[y:y+h, x:x+w]\n",
    "IF to find w,h with x1,y1,x2,y2  after finding, do minimize with width,height:\n",
    "x1/w, y1/h, w/w, h/h.\n",
    "\n",
    "These all are the conventions of converting required format \n",
    "\n",
    "But model_syntax will be like:\n",
    "ymin = ymin*height\n",
    "xmin = xmin*width\n",
    "xmax = xmax*width\n",
    "ymax - ymax*height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2857c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(category_index)\n",
    "category_index = df.to_dict('series')\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16505400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
